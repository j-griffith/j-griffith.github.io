---
layout: post
title: The Problem with SDS under Cinder - Part 2
date: 2014-06-17 16:26:13.000000000 -06:00
categories: []
tags: []
status: publish
type: post
published: true
meta:
  _edit_last: '31487780'
  _publicize_pending: '1'
  geo_public: '0'
author:
  login: jgriffith8
  email: john.griffith8@gmail.com
  display_name: jgriffith8
  first_name: ''
  last_name: ''
excerpt: !ruby/object:Hpricot::Doc
  options: {}
---
<p>Ok... so there's been all sorts of comments and follow up blogs from my initial posting.  The most recent of which came from my good friend Kenneth Hui <strong><a title="The problem SDS under OpenStack/Cinder solves" href="http://cloudarchitectmusings.com/2014/06/17/the-problem-sds-under-openstack-cinder-solves/" target="_blank">The problem sds under openstack cinder solves</a>.  </strong>I'm likely to say some "unpopular" things in this post and I really hope that Ken and the folks at EMC don't take it the wrong way.  They're a great group, I really enjoy debating with them, and even more, I enjoy talking about OpenStack and common interests that we have.  I also really value Kens viewpoint and friendship, he's a great guy and have the utmost respect for him both personally and technically.</p>
<p>Ken makes some pretty good points (as does the rest of the EMC team).  Here's the problem though, I don't see VIPR (or any of the sudden influx of these storage abstraction solutions calling themselves SDS) really doing anything that unique or different.  Ken makes a great point about true SDS being a separation of control and data planes and most importantly this functionality has requirements on the storage platform itself.  I couldn't agree more, and I don't see how VIPR is offering me anything different here than what we're already doing in Cinder; more importantly I don't see how it could.</p>
<p>Another issue I've been having is mixed messages from EMC on what VIPR is and what it supports.  In Atlanta I was told I was incorrect and that VIPR was strictly for consolidation of EMC products, but again I see things like this: <strong><a href="https://community.emc.com/thread/194554" target="_blank">Which</a><a href="https://community.emc.com/thread/194554" target="_blank"> Storage Platforms are supported by VIPR SRM</a>.  </strong>Many of those devices are in fact devices that already have drivers in Cinder and provide the same abstraction that VIPR would provide.  Are you saying that VIPR has some magic that none of us know about that actually changes what can be done with the device?  Or that EMC and the VIPR team have discovered some hidden programmatic interface to NetAPP, IBM, HDS and HP devices that the engineers who are full time contributors to Cinder currently simply didn't know about?  I'm failing to see what the value add is here for OpenStack (or anybody for that matter).  What is VIPR actually providing that Cinder doesn't or can't in terms of these Block devices?</p>
<p>Ken also mentions things in his post like "exposing unique features" but I don't understand how that is being done any differently with VIPR than it is in Cinder today?  My point here is that you're using the same API so how is it different?  Seems to me you'd still use the same mechanism we use in Cinder today of Volume-Types or Capability scheduling.</p>
<p>Finally, one of the most common arguments I get from EMC on this topic is "Neutron does it this way", well...  comparing block storage and Networking isn't very fair in my opinion.  Networking is vastly different and in my opinion more complex.  That being said, Neutron has some challenges as a result of this model in my opinion (and others as well).  I'm not criticizing Neutron or the great folks that are working on it in any way at all; but I will say that it's probably not a good argument to use here (at least not with me).</p>
<p>So, where are we... with all of my ranting and gibberish nonsense that frankly probably nobody really cares about anyway; I've come pretty close to just accepting the fact that the VIPR driver is likely going to be included in Cinder for the Juno release.  I'm struggling with this because on the tail of it comes everybody elses duplicate abstraction (Atlantis, ProphetStor and a list of others that may not be "public" yet).  I'm not sure how to handle this, I still would prefer that they aren't shipped in OpenStack but provided as an option for folks to use with OpenStack as outside products if they so desire.  Alternatively, I don't think they should be called drivers, I think they should probably be plugins that are designed higher up in the architecture (sit just below the API), so if you don't want to use Cinder for anything other than an API that's your choice, go for it.</p>
<p>At any rate, the only good thing is that they say imitation is the most sincere form of flattery; if that's the case all of the Cinder team (and the original nova-volume team) should be pretty flattered because it seems that there are a vast number of vendors out there that are imitating Cinder and trying to productize it.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
